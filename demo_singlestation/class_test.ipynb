{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trainer for pretrain phase. \"\"\"\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tqdm\n",
    "import datetime\n",
    "import psutil\n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.nn as nn\n",
    "from dataset_loader import *\n",
    "from utils.misc import Averager, Resize_Feature,Timer\n",
    "#from utils.Tool import *\n",
    "from Network_torch import *\n",
    "from scipy import io\n",
    "from testing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_type='VGGDepthSingle256', loss_type='BCE', ref_type='Constant', num_workers=1, pre_max_epoch=50, pre_batch_size=100, pre_lr=0.0001, pre_gamma=0.1, pre_step_size=20, In_channels=1, Out_channels=256, pre_optimizer='Adam', pre_custom_momentum=0.9, pre_custom_weight_decay=0.0005, pre_init_weights=None, pre_val_epoch=1, test_dataset_dir='./', test_dataset_name='Depth_Single_station_CESO', pre_input_data='testing_data/station3_input.hdf5', test_batch_size=100, test_init_weights='./well_trained_model/CESI_epoch_300.pth', test_height=96, test_width=192)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Basic parameters\n",
    "    #####CHECKPOINT############################################################################################################ \n",
    "    parser.add_argument('--model_type', type=str, default='VGGDepthSingle256', choices=['UNet','VGGDepthSingle256','VGGDepth','VGGDepthSingle','VGG19Depth','VGGDepth1','VGGDepth1024', 'VGGDepth256','VGG16Attention','UNetDepth']) # The network architecture\n",
    "    parser.add_argument('--loss_type', type=str, default='BCE', choices=['BCE', 'MSE']) # The loss function    \n",
    "\n",
    "    # parser.add_argument('--phase', type=str, default='pre_train', choices=['pre_train', 'fine_tune', 'testing', 'testing_old']) # Phase    \n",
    "    parser.add_argument('--ref_type', type=str, default='Constant', choices=['Constant','Reference'])# The Reference Velocity Type\n",
    "    # parser.add_argument('--ref_num', type=int, default=6)# The Reference Velocity Number\n",
    "    # parser.add_argument('--seed', type=int, default=0) # Manual seed for PyTorch, \"0\" means using random seed\n",
    "    # parser.add_argument('--gpu', default='0') # GPU id\n",
    "    parser.add_argument('--num_workers', type=int, default=1) # Number of CPU cores used for data loading\n",
    "    \n",
    "    # parser.add_argument('--Predthre', type=float, default=0.1)\n",
    "\n",
    "    # parser.add_argument('--pre_dataset', type=str, default='COCO') # The pre-trained dataset\n",
    "    # parser.add_argument('--pre_dataset_ver', type=str, default='COCO') # The pre-trained dataset version\n",
    "    parser.add_argument('--pre_max_epoch', type=int, default=50) # Epoch number for pre-train phase\n",
    "    parser.add_argument('--pre_batch_size', type=int, default=100) # Batch size for pre-train phase\n",
    "    parser.add_argument('--pre_lr', type=float, default=0.0001) # Learning rate for pre-train phase\n",
    "    parser.add_argument('--pre_gamma', type=float, default=0.1) # Gamma for the pre-train learning rate decay\n",
    "    parser.add_argument('--pre_step_size', type=int, default=20) # The number of epochs to reduce the pre-train learning rate\n",
    "    #####CHECKPOINT############################################################################################################\n",
    "    parser.add_argument('--In_channels', type=int, default=1) # The number of epochs to reduce the pre-train learning rate\n",
    "    parser.add_argument('--Out_channels', type=int, default=256) # The number of epochs to reduce the pre-train learning rate\n",
    "    \n",
    "    parser.add_argument('--pre_optimizer', type=str, default='Adam', choices=['Adam', 'sgd']) # optimizer for pre-train phase\n",
    "    parser.add_argument('--pre_custom_momentum', type=float, default=0.9) # Momentum for the optimizer during pre-train    \n",
    "    parser.add_argument('--pre_custom_weight_decay', type=float, default=0.0005) # Weight decay for the optimizer during pre-train\n",
    "    parser.add_argument('--pre_init_weights', type=str, default=None)# The pre-trained weights for pre-train phase\n",
    "    parser.add_argument('--pre_val_epoch', type=int, default=1) # The epoch interval for validation\n",
    "    # parser.add_argument('--pre_early_stop', type=int, default=10) # The number of epochs to early stop during pre-train\n",
    "    # parser.add_argument('--pre_early_stop_type', type=str, default='loss', choices=['loss','VMAE'])# The pre-trained weights for pre-train phase\n",
    "    # parser.add_argument('--pre_dt', type=float, default=2, help='dt of the dataset, Unit: ms')\n",
    "    # parser.add_argument('--pre_nt', type=int, default=1505, help='number of time sampling points')\n",
    "\n",
    "\n",
    "    # Parameters for testing\n",
    "    #####CHECKPOINT############################################################################################################\n",
    "    parser.add_argument('--test_dataset_dir', type=str, default='./')# The pre-trained dataset folder\n",
    "    parser.add_argument('--test_dataset_name', type=str, default='Depth_Single_station_CESO') # The pre-trained dataset\n",
    "    parser.add_argument('--pre_input_data', type=str, default='testing_data/station3_input.hdf5')\n",
    "    #parser.add_argument('--pre_label_data', type=str, default='Test_label_depth_17-05-1.3.hdf5')\n",
    "\n",
    "    parser.add_argument('--test_batch_size', type=int, default=100) # Batch size for testing\n",
    "    ## CHECKPOINT############################################################################################################\n",
    "    parser.add_argument('--test_init_weights', type=str, default='./well_trained_model/CESI_epoch_300.pth')# The pre-trained weights for testing\n",
    "    parser.add_argument('--test_height', type=int, default=96)\n",
    "    parser.add_argument('--test_width', type=int, default=192)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    # 在这里可以使用 args 来访问解析后的参数\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = DepthTestingLearner(args)   # Create an instance of the class\n",
    "# train = instance.test() # Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Station Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of testing samples is 6612\n",
      "The size of testing samples is 96 x 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:01<00:00, 49.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test is completed!\n",
      "The result is saved in ./logs_fortest/test/Depth_Single_station_CESO_lr0.0001_batch100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "instance = SingleStationDepthTestingLearner(args)   # Create an instance of the class\n",
    "train = instance.test()  # Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = TestingLearner(args)   # Create an instance of the class\n",
    "# train = instance.test() # Start training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
